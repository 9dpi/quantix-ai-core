"""
Quantix AI - Analytics Schema Definition
Defines analytics_snapshots_v1, analytics_stats_v1, and analytics_drift_v1.
"""

import os
from supabase import create_client, Client
from dotenv import load_dotenv
from loguru import logger

def migrate():
    # Load env
    env_path = os.path.join('backend', '.env')
    load_dotenv(env_path)
    
    url = os.environ.get("SUPABASE_URL")
    key = os.environ.get("SUPABASE_SERVICE_ROLE_KEY")
    
    if not url or not key:
        logger.error("‚ùå Supabase credentials not found")
        return

    # In a real scenario, we'd use a migration tool or execute SQL via a client that supports it.
    # Supabase Python client doesn't support raw DDL well, usually done via Dashboard SQL Editor.
    
    logger.info("üìÑ [DDL] Use the following SQL in Supabase Dashboard:")
    
    sql = """
    -- üîí analytics_snapshots_v1 (append-only)
    CREATE TABLE IF NOT EXISTS analytics_snapshots_v1 (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        snapshot_id TEXT UNIQUE,
        date DATE,
        asset TEXT,
        timeframe TEXT,
        structure_state TEXT,
        dominance NUMERIC,
        confidence NUMERIC,
        evidence_json JSONB,
        created_at TIMESTAMPTZ DEFAULT NOW()
    );

    -- üîí analytics_stats_v1
    CREATE TABLE IF NOT EXISTS analytics_stats_v1 (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        metric TEXT,
        value NUMERIC,
        window TEXT,
        computed_at TIMESTAMPTZ DEFAULT NOW()
    );

    -- üîí analytics_drift_v1
    CREATE TABLE IF NOT EXISTS analytics_drift_v1 (
        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
        metric TEXT,
        drift_score NUMERIC,
        status TEXT,
        baseline_period TEXT,
        computed_at TIMESTAMPTZ DEFAULT NOW()
    );
    """
    print(sql)
    logger.success("‚úÖ Analytics Schema Definition Ready.")

if __name__ == "__main__":
    migrate()
